Meeting Minutes: 9/26/19

Design:
    What are we trying to build?
        - A crawler that acquires documents from URLs
        - Sends either documents or links back to Link Analysis
    How do we know it works?
        - 
    How do we know it scales?
        - 
    Ethical considerations?
        - Works within ethical standards like robots.txt

Architecture:
    - Takes in a URL (and maybe a frequency to poll)
    - Sends list of links to Link Analysis (JSON)
    - Sends full text (HTML) to Text Transformation
